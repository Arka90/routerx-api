import { Worker, Job } from "bullmq";
import { runFullProbe } from "../modules/probe/probe.service";
import { db } from "../core/db/client";
import { sendAlert } from "../modules/notifications/notifier";
import { openIncident, resolveIncident } from "../modules/incident/incident.service";
import { connectionOptions } from "../core/queue/redis";
import { classifyFailure } from "../domain/diagnostics/root-cause.classifier";
import { getCertificateExpiry } from "../domain/diagnostics/tls-expiry.checker";
import { sendTlsExpiryAlert } from "../modules/notifications/email.provider";

/**
 * RULES
 * -----
 * DOWN: 3 consecutive failures
 * UP:   2 consecutive successes after DOWN
 */

const FAILURE_THRESHOLD = 3;
const RECOVERY_THRESHOLD = 2;

const worker = new Worker(
  "monitor-check",
  async (job: Job) => {
    const { monitorId, url } = job.data;

    // -----------------------------
    // 1ï¸âƒ£ Verify monitor still exists
    // -----------------------------
    const monitorRow = db
      .prepare(`
        SELECT id, user_id, confirmed_status, consecutive_failures, consecutive_successes,
               tls_expiry_at, tls_alerted_days
        FROM monitors
        WHERE id = ?
      `)
      .get(monitorId) as any;

    if (!monitorRow) {
      console.log(`âš ï¸ Ignoring stale job for deleted monitor ${monitorId}`);
      return;
    }

    let failures = monitorRow.consecutive_failures ?? 0;
    let successes = monitorRow.consecutive_successes ?? 0;
    let confirmedStatus = monitorRow.confirmed_status ?? "UP";

    // -----------------------------
    // 2ï¸âƒ£ Run probe
    // -----------------------------
    const { diagnosis, dns, tcp, tls, http } = await runFullProbe(url);
    const rootCause = classifyFailure({ dns, tcp, tls, http });
    const currentStatus: "UP" | "DOWN" | "SLOW" = diagnosis.status;

    // -----------------------------
    // 3ï¸âƒ£ Failure handling
    // -----------------------------
    if (currentStatus === "DOWN") {
      failures++;
      successes = 0;

      console.log(`âš ï¸ ${url} failure ${failures}/${FAILURE_THRESHOLD}`);

      if (failures >= FAILURE_THRESHOLD && confirmedStatus !== "DOWN") {
        confirmedStatus = "DOWN";

        // ðŸ”´ Record incident start
        openIncident(monitorId, rootCause);

        console.log(`ðŸš¨ CONFIRMED DOWN: ${url}`);

        // await sendAlert({
        //   monitorId,
        //   url,
        //   status: "DOWN",
        //   checkedAt: new Date(),
        // });
      }
    }

    // -----------------------------
    // 4ï¸âƒ£ Recovery handling
    // -----------------------------
    else {
      successes++;
      failures = 0;

      if (confirmedStatus === "DOWN") {
        console.log(`ðŸ§ª Recovery check ${successes}/${RECOVERY_THRESHOLD} for ${url}`);
      }

      if (confirmedStatus === "DOWN" && successes >= RECOVERY_THRESHOLD) {
        confirmedStatus = "UP";

        // ðŸŸ¢ Resolve open incident
        resolveIncident(monitorId);

        console.log(`ðŸŸ¢ RECOVERED: ${url}`);

        // await sendAlert({
        //   monitorId,
        //   url,
        //   status: "UP",
        //   checkedAt: new Date(),
        // });
      }
    }

    // -----------------------------
    // 5ï¸âƒ£ Persist monitor state
    // -----------------------------
    let tlsExpiryAt: string | null = monitorRow.tls_expiry_at ?? null;
    let tlsAlertedDays: string = monitorRow.tls_alerted_days ?? "";

    // -----------------------------
    // 5.5ï¸âƒ£ TLS certificate expiry check
    // -----------------------------
    try {
      const hostname = new URL(url).hostname;
      const expiryDate = await getCertificateExpiry(hostname);

      if (expiryDate) {
        tlsExpiryAt = expiryDate.toISOString();
        const now = new Date();
        const daysLeft = (expiryDate.getTime() - now.getTime()) / (1000 * 60 * 60 * 24);

        const alertedSet = new Set(
          tlsAlertedDays ? tlsAlertedDays.split(",").map(Number) : []
        );

        // If cert renewed (expiry > 7 days), reset alerts
        if (daysLeft > 7) {
          if (alertedSet.size > 0) {
            console.log(`ðŸ”„ TLS cert renewed for ${url}, resetting alerts`);
          }
          tlsAlertedDays = "";
        } else {
          // Determine which threshold to alert on
          let threshold: number | null = null;
          if (daysLeft <= 1 && !alertedSet.has(1)) {
            threshold = 1;
          } else if (daysLeft <= 3 && !alertedSet.has(3)) {
            threshold = 3;
          } else if (daysLeft <= 7 && !alertedSet.has(7)) {
            threshold = 7;
          }

          if (threshold !== null) {
            // Look up owner email
            const owner = db
              .prepare(`SELECT email FROM users WHERE id = ?`)
              .get(monitorRow.user_id) as any;

            if (owner?.email) {
              await sendTlsExpiryAlert(owner.email, url, expiryDate, daysLeft);
            }

            alertedSet.add(threshold);
            tlsAlertedDays = Array.from(alertedSet).join(",");
            console.log(`ðŸ”” TLS expiry alert sent for ${url} â€” ${Math.floor(daysLeft)}d left (threshold: ${threshold}d)`);
          } else {
            console.log(`ðŸ”’ TLS cert for ${url} expires in ${Math.floor(daysLeft)}d (already alerted)`);
          }
        }
      }
    } catch (err) {
      console.error(`âš ï¸ TLS expiry check failed for ${url}:`, err);
    }

    db.prepare(`
      UPDATE monitors
      SET
        consecutive_failures = ?,
        consecutive_successes = ?,
        confirmed_status = ?,
        tls_expiry_at = ?,
        tls_alerted_days = ?
      WHERE id = ?
    `).run(failures, successes, confirmedStatus, tlsExpiryAt, tlsAlertedDays, monitorId);

    // -----------------------------
    // 6ï¸âƒ£ Store probe history
    // -----------------------------
    db.prepare(`
      INSERT INTO probe_results
      (monitor_id, dns, tcp, tls, ttfb, status, root_cause, http_status_code)
      VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    `).run(
      monitorId,
      dns?.time ?? null,
      tcp?.time ?? null,
      tls?.time ?? null,
      http?.ttfb ?? null,
      currentStatus,
      rootCause,
      http?.statusCode ?? null,
    );
  },
  {
    connection: connectionOptions,

    // IMPORTANT: SQLite safety
    concurrency: 1,
  }
);

// -----------------------------
// Worker lifecycle logging
// -----------------------------
worker.on("ready", () => {
  console.log("ðŸŸ¢ Monitor worker connected to Redis");
});

worker.on("active", (job) => {
  console.log(`ðŸ”Ž Checking ${job.data.url}`);
});

worker.on("completed", (job) => {
  console.log(`âœ… Completed ${job.data.url}`);
});

worker.on("failed", (job, err) => {
  console.log(`âŒ Failed ${job?.data?.url}`, err.message);
});

worker.on("error", (err) => {
  console.error("Worker error:", err);
});

// keep process alive
process.stdin.resume();

// graceful shutdown
process.on("SIGINT", async () => {
  await worker.close();
  process.exit(0);
});

process.on("SIGTERM", async () => {
  await worker.close();
  process.exit(0);
});
